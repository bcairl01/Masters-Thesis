\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {VI. }Perception and Navigation}{73}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\newlabel{ch::navigation}{{VI}{73}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Flatland navigation and goal (feature) tracking}{73}}
\citation{ArambulaCosio2004}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}LIDAR-based Potential-Fields Algorithm}{74}}
\newlabel{eq::min_dis_potential_function}{{(6.2)}{74}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Potential field, $f(x)$ with $d_{min}=0.4m$ given an environment with with obstacles.\relax }}{75}}
\newlabel{fig::potential_field}{{33}{75}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Simulated potential field navigation results}{76}}
\citation{opencv_library}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces Path (shown in yellow) taken by robot through a simulated set of rooms and halls using the LIDAR-based potential fields navigation scheme.\relax }}{77}}
\newlabel{fig::potential_field_results}{{34}{77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.3}Incorporation of Camera-based Feature-Tracking}{77}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Path (shown in yellow) taken by robot through a simulated set of rooms and obstacles.\relax }}{78}}
\newlabel{fig::potential_field_results_obstacles}{{35}{78}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Path (shown in yellow) taken by robot through a real-life lab setting showing the robot's view of the goal marker.\relax }}{80}}
\newlabel{fig::potential_field_results_real}{{36}{80}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Towards Rough Terrain Navigation}{81}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Terrain Mapping from 2D scans}{81}}
\newlabel{ssec::terrain_mapping}{{6.2.1}{81}}
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces LIDAR swept over a range of angles, $\theta _{b,x} \in [\theta _{b,x,1}^{r},\theta _{b,x,N}^{r}]$. \relax }}{81}}
\newlabel{fig::sensor_sweep}{{37}{81}}
\newlabel{eq::world_to_sensor}{{(6.7)}{82}}
\newlabel{eq::scan_to_segment}{{(6.8)}{82}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Height-map Generation from 3D point cloud}{82}}
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces Original 3D point-cloud of terrain patch \emph  {(top)} and corresponding view from robot's on-board camera \emph  {(bottom)}.\relax }}{83}}
\newlabel{fig::pointcloud_terrain_patch}{{38}{83}}
\citation{opencv_learn_immorph}
\newlabel{eq::toheightmapframe}{{(6.10)}{84}}
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces Relative height-map \emph  {(left)} and its corresponding gradient \emph  {(right)}.\relax }}{85}}
\newlabel{fig::heightmap_terrain_patch}{{39}{85}}
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces Height-map showing terrain variation in the $z_{{\cal  M}}$ direction.\relax }}{85}}
\newlabel{fig::heightmap_terrain_patch_ortho}{{40}{85}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}Generating a Cost-map from the Height-map}{85}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces 3D ROI point cloud to height-map conversion.\relax }}{86}}
\newlabel{alg::hmconvert}{{2}{86}}
\newlabel{eq::cost_mapping}{{(6.11)}{86}}
\newlabel{eq::cost_gamma}{{6.2.3}{86}}
\citation{Rusu2009}
\@writefile{lof}{\contentsline {figure}{\numberline {41}{\ignorespaces Projections of a sample cost map generated from the height-map shown in Figure\nobreakspace  {}39\hbox {}.\relax }}{88}}
\newlabel{fig::cost_map}{{41}{88}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.4}Surface Reconstruction}{88}}
\citation{Mitra2003}
\citation{Castillo2013}
\citation{Pearson1901}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Finding good places to step from a 3D point cloud.\relax }}{89}}
\newlabel{alg::goodspacestostep}{{3}{89}}
\@writefile{lof}{\contentsline {figure}{\numberline {42}{\ignorespaces Point cloud generated from sequential scans of a room showing flat-surface candidates \emph  {(top)} and 3D Point Cloud with normal estimation \emph  {(bottom)}.\relax }}{91}}
\newlabel{fig::surface_estimation}{{42}{91}}
\@setckpt{ch6_navigation}{
\setcounter{page}{92}
\setcounter{equation}{14}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{subequation}{0}
\setcounter{part}{0}
\setcounter{chapter}{6}
\setcounter{section}{2}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{42}
\setcounter{table}{12}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{KVtest}{0}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{lotdepth}{1}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{3}
\setcounter{ALG@line}{10}
\setcounter{ALG@rem}{10}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{theorem}{0}
\setcounter{definition}{0}
\setcounter{lemma}{0}
\setcounter{remark}{0}
\setcounter{example}{0}
\setcounter{assumption}{0}
}
